<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>• Goldberg, D. E., Holland, J. H. (1988). Genetic algorithms and machine learning. Machine Learning, 3(2), 95–99.</p> <p>• Holland, J. H. (1992). Genetic algorithms. Scientific American, 267(1), 66–73.</p> <p>• Kumar, S.; Jain, S.; Sharma, H. Genetic algorithms. In Advances in Swarm Intelligence for Optimizing Problems in Computer Science; Taylor and Francis Group: Abingdon, UK, 2018; pp. 27–52.</p> <p>• Turing, A. M.: 1948, ‘Intelligent Machinery’, in D. Ince (ed.), Mechanical Intelligence, North-Holland, Amsterdam, pp. 87–106.</p> <p>• R. W. Anderson and M. Conrad. “Hans J. Bremermann:A pioneer in mathematical biology,” BioSystems, Vol. 34, no. 1-3, pp.1-10, 1995.</p> <p>• H. J. Bremermann, “Optimization through evolution and recombination,” in SelfOrganizing Systems. M. C. Yovits, G. T. Jacobi, and G. D. Goldstine, Eds. Washington, DC: Spartan Books, pp. 93-106, 1962.</p> <p>• Holland JH, Koza JR (1992) Genetic programming. Sci Am 267:66–72</p> <p>• SPEARS, W. M., JONG, K. A. D., BACK ¨ , T., FOGEL, D. B., AND DE GARIS, H. 1993. An overview of evolutionary computation. In Proceedings of the European Conference on Machine Learning (ECML93), P. B. Brazdil, Ed. Vol. 667. Springer Verlag, Vienna, Austria, 442–459.</p> <p>• Mirjalili S. Genetic algorithm. Evolutionary algorithms and neural networks. Springer; 2019. p. 43–55.</p> <p>• Lipowski and D. Lipowska, “Roulette-wheel selection via stochastic acceptance,” Physica A, Stat. Mechan. Appl., vol. 391, no. 6, pp. 2193–2196, 2012.</p> <p>• Goldberg, D. E. (1990). A note on Boltzmann tournament selection for genetic algorithms and population-oriented simulated annealing. Complex Systems, 4(4), 445–460.</p> <p>• Miller, B. L., Goldberg, D. E. (1995). Genetic algorithms, tournament selection, and the effects of noise. Complex Systems, 9(3), 193–212.</p> <p>• Kumar, R. (2012). Blending roulette wheel selection rank selection in genetic algorithms. International Journal of Machine Learning and Computing, 2(4), 365.</p> <p>• Syswerda, G. (1991). A study of reproduction in generational and steady-state genetic algorithms. In Foundations of genetic algorithms (Vol. 1, pp. 94–101). Elsevier.</p> <p>• Blickle, T., Thiele, L. (1996). A comparison of selection schemes used in evolutionary algorithms. Evolutionary Computation, 4(4), 361–394. 54 4 Genetic Algorithm.</p> <p>• Collins, R. J., Jefferson, D. R. (1991). Selection in massively parallel genetic algorithms (pp. 249–256). University of California (Los Angeles), Computer Science Department.</p> <p>• Ishibuchi, H., Yamamoto, T. (2004). Fuzzy rule selection by multiobjective genetic local search algorithms and rule evaluation measures in data mining. Fuzzy Sets and Systems, 141(1), 59–88.</p> <p>• Hutter, M. (2002). Fitness uniform selection to preserve genetic diversity. In Proceedings of the 2002 Congress on Evolutionary Computation, CEC’02 (Vol. 1, pp. 783–788). IEEE.</p> <p>• Grefenstette, J. J. (1989). How genetic algorithms work: A critical look at implicit parallelism. In Proceedings of the 3rd International Joint Conference on Genetic Algorithms (ICGA89).</p> <p>• Syswerda, G. (1989). Uniform crossover in genetic algorithms. In Proceedings of the Third International Conference on Genetic Algorithms (pp. 2–9). Morgan Kaufmann Publishers.</p> <p>• Semenkin, E., Semenkina, M. (2012). Self-configuring genetic algorithm with modified uniform crossover operator. In International Conference in Swarm Intelligence (pp. 414–421). Heidelberg: Springer.</p> <p>• Mehboob U, Qadir J, Ali S, Vasilakos A (2016) Genetic algorithms in wireless networking: techniques, applications, and issues. Soft Comput 20:2467–2501.</p> <p>• Hu, X. B., Di Paolo, E. (2007). An efficient genetic algorithm with uniform crossover for the multi-objective airport gate assignment problem. In IEEE Congress on Evolutionary Computation, 2007 (CEC 2007) (pp. 55–62). IEEE.</p> <p>• Tsutsui, S., Yamamura, M., Higuchi, T. (1999). Multi-parent recombination with simplex crossover in real coded genetic algorithms. In Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 1 (pp. 657–664).Morgan Kaufmann Publishers Inc.</p> <p>• Bck, T., Fogel, D. B., Michalewicz, Z. (Eds.). (2000). Evolutionary computation 1: Basic algorithms and operators (Vol. 1). CRC press.</p> <p>• Oliver, I. M., Smith, D., Holland, J. R. (1987). Study of permutation crossover operators on the travelling salesman problem. In Proceedings of the Second International Conference on Genetic Algorithms and their Applications, July 28–31, 1987 at the Massachusetts Institute of Technology, Cambridge, MA. Hillsdale, NJ: L. Erlhaum Associates.</p> <p>• Davis, L. (1985). Applying adaptive algorithms to epistatic domains. In IJCAI (Vol. 85, pp. 162–164).</p> <p>• Whitley, D., Timothy, S., Daniel, S. Schedule optimization using genetic algorithms. In D. Lawrence (Ed.) 351–357.</p> <p>• Grefenstette, J., Gopal, R., Rosmaita, B., Van Gucht, D. (1985). Genetic algorithms for the traveling salesman problem. In Proceedings of the first International Conference on Genetic Algorithms and their Applications (pp. 160–168).</p> <p>• Louis, S. J., Rawlins, G. J. (1991). Designer genetic algorithms: Genetic algorithms in structure design. In ICGA (pp. 53–60).</p> <p>• Eshelman, L. J., Caruana, R. A., Schaffer, J. D. (1989). Biases in the crossover landscape. In Proceedings of the Third International Conference on Genetic Algorithms(pp. 10–19). Morgan Kaufmann Publishers Inc.</p> <p>• Lambora, K. Gupta, K. Chopra, Genetic algorithm- a literature review, in: International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), Faridabad, India 2019, 2019, pp. 380–384.</p> <p>• Deep, K., Thakur, M. (2007). A new mutation operator for real coded genetic algorithms. Applied Mathematics and Computation, 193(1), 211–230.</p> <p>• Srinivas, M., Patnaik, L. M. (1994). Adaptive probabilities of crossover and mutation in genetic algorithms. IEEE Transactions on Systems, Man, and Cybernetics, 24(4), 656–667.</p> <p>• Neubauer, A. (1997). A theoretical analysis of the non-uniform mutation operator for the modified genetic algorithm. In IEEE International Conference on Evolutionary Computation (pp. 93–96). IEEE.</p> <p>• Hinterding, R. (1995). Gaussian mutation and self-adaption for numeric genetic algorithms. In IEEE International Conference on Evolutionary Computation (Vol. 1, p. 384). IEEE.</p> <p>• Tsutsui, S., Fujimoto, Y. (1993). Forking genetic algorithm with blocking and shrinking modes (fGA). In ICGA (pp. 206–215).</p> <p>• Oosthuizen, G. D. (1987). Supergran: A connectionist approach to learning, integrating genetic algorithms and graph induction. In Proceedings of the second International Conference on Genetic Algorithms and their Applications, July 28–31, 1987 at the Massachusetts Institute of Technology, Cambridge, MA. Hillsdale, NJ: L. Erlhaum Associates.</p> <p>• Mauldin, M. L. (1984). Maintaining diversity in genetic search. In AAAI (pp. 247–250).</p> <p>• Ankenbrandt, C. A. (1991). An extension to the theory of convergence and a proof of the time complexity of genetic algorithms. In Foundations of genetic algorithms (Vol. 1, pp. 53–68). Elsevier.</p> <p>• T. Mitchell, Machine Learning. Springer, 1997.</p> <p>• Q. Yao, M. Wang, E. H. Jair, I. Guyon, Y.-Q. Hu, Y.-F. Li, W.- W. Tu, Q. Yang, and Y. Yu. 2018. Taking human out of learning applications: A survey on automated machine learning. arXiv preprint arXiv:1810.13306.</p> <p>• Goodfellow, Y. Bengio, A. Courville, and Y. Bengio, Deep learning. MIT Press, 2016.</p> <p>• C. Kuo and F. Golnaraghi, Automatic control systems. Prentice-Hall Englewood Cliffs, NJ, 1995.</p> <p>• G. Chandrashekar and F. Sahin, “A survey on feature selection methods,” Computers Electrical Engineering, vol. 40, no. 1, pp. 16–28, 2014.</p> <p>• Kunpeng Liu, Yanjie Fu, Le Wu, Xiaolin Li, Charu Aggarwal, and Hui Xiong. 2021. Automated feature selection: A reinforcement learning perspective. IEEE Transactions on Knowledge and Data Engineering (2021).</p> <p>• J. M. Kanter and K. Veeramachaneni, “Deep feature synthesis: Towards automating data science endeavors,” in IEEE International Conference on Data Science and Advanced Analytics, 2015, pp. 1–10.</p> <p>• G. Katz, E. C. R. Shin, and D. Song, “Explorekit: Automatic feature generation and selection,” in International Conference on Data Mining, 2016, pp. 979–984.</p> <p>• M. Feurer, K. Eggensperger, S. Falkner, M. Lindauer, and F. Hutter “Auto-sklearn 2.0: The next generation,” 2020, arXiv: 2007:04074.</p> <p>• Thornton, F. Hutter, H. Hoos, and K. Leyton-Brown, “Auto- WEKA: combined selection and hyperparameter optimization of classification algorithms,” in Proc. of KDD’13, 2013, pp. 847–855.</p> <p>• Komer, J. Bergstra, and C. Eliasmith, “Hyperopt-sklearn: Automatic hyperparameter configuration for scikit-learn,” in ICML Workshop on AutoML, 2014.</p> <p>• M. Feurer, A. Klein, K. Eggensperger, J. Springenberg, M. Blum, and F. Hutter, “Efficient and robust automated machine learning,” in Proc. of NeurIPS’15, 2015, pp. 2962–2970.</p> <p>• R. Olson, N. Bartley, R. Urbanowicz, and J. Moore, “Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science,” in Proc. of GECCO’16, 2016, pp. 485–492.</p> <p>• H. Jin, Q. Song, and X. Hu, “Auto-Keras: An efficient neural architecture search system,” in Proc. of KDD’19, 2019, pp. 1946–1956.</p> <p>• J.Shapiro: Genetic algorithms in machine learning. Lecture notes in computer science (Vol. 2049/2001, pp. 146–168). (2001).</p> <p>• H. Ishigami, T. Fukuda, and F. Arai, “Structure optimization of fuzzy neural network by genetic algorithm,” Fuzzy Sets Syst., vol. 71, no. 3, pp. 257–264, 1995.</p> <p>• C.M. Higgins and R.M. Goodman, Learning fuzzy rulebased neural networks for function approximation, Proc. IEEE IJCNN, Vol. 1 (1992) 251-256.</p> <p>• S. Horikawa, T. Furuhashi et al., A study on fuzzy modeling using fuzzy neural networks, Proc. IFES (1991) 562-573.</p> <p>• H. Nomura et al., A self-tuning method of fuzzy reasoning by genetic algorithm, Proc. lnternat. Fuzzy Systems and Intelligent Control Conf. (1992) 236-245.</p> <p>• Tsiakmaki M, Kostopoulos G, Kotsiantis S, Ragos O. Fuzzy-based active learning for predicting student academic performance usingautoML: a step-wise approach.J Comput High Educ. 2021;33:1-33.</p> <p>• Tsiakmaki, M., Kostopoulos, G., Kotsiantis, S., Ragos, O. (2020). Fuzzy-based active learning for predicting student academic performance. In Proceedings of the 6th international conference on engineering MIS 2020 (pp. 1–6).</p> <p>• Lewis, D., Gale, W. (1994). A sequential algorithm for training text classifiers. In SIGIR’94 (pp. 3–12).</p> <p>• Li, C.-L., Ferng, C.-S., Lin, H.-T. (2012). Active learning with hinted support vector machine. In Asian Conference on Machine Learning (pp. 221–235).</p> <p>• Huang, S.-J., Jin, R., Zhou, Z.-H. (2010). Active learning by querying informative and representative examples. In J. D. Lafferty, C. K. Williams, J. Shawe-Taylor, R. S. Zemel, A. Culotta (Eds.), Advances in neural information processing systems 23. (pp. 892–900). Curran Associates.</p> <p>• Ramirez-Loaiza, M., Sharma, M., Kumar, G., Bilgic, M. (2017). Active learning: An empirical study of common baselines. Data Mining and Knowledge Discovery, 31(2), 287–313.</p> <p>• P. Evans, B. Xue, and M. Zhang. An adaptive and near parameter-free evolutionary computation approach towards true automation in automl. arXiv preprint arXiv:2001.10178, 2020.</p> <p>• Chen and C. Zhao, “Particle swarm optimization with adaptive population size and its application,” Applied Soft Computing, vol. 9, no. 1, pp. 39–48, 2009.</p> <p>• Thierens, “Adaptive mutation rate control schemes in genetic algorithms,” in Proceedings of the 2002 Congress on Evolutionary Computation. CEC’02 (Cat. No. 02TH8600), vol. 1. IEEE, 2002, pp. 980–985.</p> <p>• N. N. Vorobiev, Fibonacci numbers. Birkh¨auser, 2012.</p> <p>• P. Gijsbers, E. LeDell, J. Thomas, S. Poirier, B. Bischl, and J. Vanschoren, “An open source automl benchmark,” arXiv preprint arXiv:1907.00909, 2019.</p> <p>• Owoyele, O., Pal, P., Torreira, A., Probst, D., Shaxted, M., Wilde, M., and P. Senecal. 2021. “Application of an automated machine learninggenetic algorithm (AutoML-GA) coupled with computational fluid dynamics simulations for rapid engine design optimization”. International Journal of Engine Research 22(7):2407-2764.</p> <p>• Owoyele O, Pal P and Torreira AV. An automated machine learninggenetic algorithm framework with active learning for design optimization. J Energy Resour Technol 2021; 143(8): 082305.</p> <p>• Van der Laan MJ, Polley EC and Hubbard AE. Super learner. Statistical Applications in Genetics and Molecular Biology 2007; 6: Article25.</p> <p>• Drucker H, Burges CJ, Kaufman L, et al. Support vector regression machines. In: Advances in neural information processing systems, Cambridge, MA: MIT Press, 1997, pp.155–161.</p> <p>• Chen T and Guestrin C. Xgboost: a scalable tree boosting system. In: Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, 2016, pp.785–794. New York, NY: Association for Computing Machinery.</p> <p>• Van Der Walt S, Colbert SC and Varoquaux G. The NumPy array: a structure for efficient numerical computation. Comput Sci Eng 2011; 13: 22–30.</p> <p>• Pedregosa F, Varoquaux G, Gramfort A, et al. Scikitlearn: machine learning in Python. J Mach Learn Res 2011; 12: 2825–2830.</p> <p>• Nogueira F. Bayesian optimization: open source constrained global optimization tool for Python. 2014, https://github.com/fmfn/BayesianOptimization.</p> <p>• You, J. A Genetic Algorithm-based AutoML Approach for Large-scale Traffic Speed Prediction. In Proceedings of the 2020 IEEE 5th International Conference on Intelligent Transportation Engineering (ICITE), Beijing, China, 11–13 September 2020; IEEE: New York, NY, USA, 2020.</p> <p>• Polus, M. Livneh, and J. Craus, ”Effect of Traffic and Geometric Measures on Highway Average Running Speed.,” Transp. Res. Rec., pp. 34–39, 1984.</p> <p>• O. W. W. Yang, ”http://www.paper.edu.cn Traffic Prediction Using FARIMA Models,” pp. 3–7, 1999.</p> <p>• Bratsas, K. Koupidis, J. M. Salanova, K. Giannakopoulos, A. Kaloudis, and G. Aifadopoulou, ”A comparison of machine learning methods for the prediction of traffic speed in Urban places,” Sustain., vol. 12, no. 1, pp. 1–15, 2020, doi: 10.3390/SU12010142.</p> <p>• X. Yi, Z. Duan, T. Li, T. Li, J. Zhang, and Y. Zheng, ”CityTraffic: Modeling city-wide traffic via neural memorization and generalization approach,” Int. Conf. Inf. Knowl. Manag. Proc., vol. i, pp. 2665–2671, 2019, doi: 10.1145/3357384.3357822.</p> <p>• Y. Kim, P. Wang, Y. Zhu, and L. Mihaylova, ”A Capsule Network for Traffic Speed Prediction in Complex Road Networks,” 2018 Symp. Sens. Data Fusion Trends, Solut. Appl. SDF 2018, 2018, doi: 10.1109/SDF.2018.8547068.</p> <p>• Yu, H. Yin, and Z. Zhu, ”Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting,” IJCAI Int. Jt. Conf. Artif. Intell., vol. 2018-July, pp. 3634–3640, 2018, doi: 10.24963/ijcai.2018/505.</p> <p>• T. Epelbaum, F. Gamboa, J.-M. Loubes, and J. Martin, ”Deep Learning applied to Road Traffic Speed forecasting,” 2017.</p> <p>• S. Yang, W. Ma, X. Pi, and S. Qian, ”A deep learning approach to real-time parking occupancy prediction in transportation networks incorporating multiple spatio-temporal data sources,” Transp. Res. Part C Emerg. Technol., vol. 107, pp. 248–265, 2019.</p> <p>• L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, ”Hyperband: A novel bandit-based approach to hyperparameter optimization,” J. Mach. Learn. Res., vol. 18, no. 1, pp. 6765–6816, 2017.</p> <p>• Zhang, Zheng, Xiang Lu, and Shouqi Cao. “An efficient detection model based on improved YOLOv5s for abnormal surface features of fish.” Mathematical Biosciences and Engineering 21, no. 2 (2024): 1765-1790.</p> <p>• Lv, Zehua, Yibo Li, Siying Qian, and Liuqing Wu. “Online surface defect segmentation on aluminum strip production line using a lightweight and efficient model.” Engineering Applications of Artificial Intelligence 126 (2023): 107023.</p> <p>• Cao, Xianghong, Yixuan Su, Xin Geng, and Yongdong Wang. “YOLO-SF: YOLO for fire segmentation detection.” IEEE Access (2023).</p> <p>• Yang, Guanghui, Ziqi Qin, Jianmin Mu, Haiting Mao, Huihui Mao, and Min Han. “Efficient diagnosis of hematologic malignancies using bone marrow microscopic images: A method based on MultiPathGAN and MobileViTv2.” Computer Methods and Programs in Biomedicine 237 (2023): 107583.</p> <p>• Munir, Mustafa, William Avery, and Radu Marculescu. “MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications.” In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2210-2218. 2023.</p> <p>• Miao, Lize, Ning Li, Minglong Zhou, and Huiyu Zhou. “CBAM-Yolov5: improved Yolov5 based on attention model for infrared ship detection.” In International conference on computer graphics, artificial intelligence, and data processing (ICCAID 2021), vol. 12168, pp. 564-571. SPIE, 2022.</p> <p>• Liu, Jiehui, Hongchao Qiao, Lijie Yang, and Jinxi Guo. “Improved lightweight YOLOv4 foreign object detection method for conveyor belts combined with CBAM.” Applied Sciences 13, no. 14 (2023): 8465.</p> <p>• Chen, Boyuan, and Zichen Dang. “Fast PCB defect detection method based on FasterNet backbone network and CBAM attention mechanism integrated with feature fusion module in improved YOLOv7.” IEEE Access (2023).</p> <p>• Lin, Lin, Jie Zhang, Xu Gao, Jiancheng Shi, Cheng Chen, and Nantian Huang. “Power fingerprint identification based on the improved VI trajectory with color encoding and transferred CBAM-ResNet.” Plos one 18, no. 2 (2023): e0281482.</p> <p>• Yuan, Chuangchuang, Tonghai Liu, Fangyu Gao, Rui Zhang, and Xiaoyue Seng. “YOLOv5s-CBAM-DMLHead: A lightweight identification algorithm for weedy rice (Oryza sativa f. spontanea) based on improved YOLOv5.” Crop Protection 172 (2023): 106342.</p> <p>• Ma, Rui, Jia Wang, Wei Zhao, Hongjie Guo, Dongnan Dai, Yuliang Yun, Li Li, Fengqi Hao, Jinqiang Bai, and Dexin Ma. “Identification of maize seed varieties using MobileNetV2 with improved attention mechanism CBAM.” Agriculture 13, no. 1 (2022): 11.</p> <p>• Zhang, Yao, Hong Wang, Jiahao Liu, Xili Zhao, Yuting Lu, Tengfei Qu, Haozhe Tian, Jingru Su, Dingsheng Luo, and Yalei Yang. “A lightweight winter wheat planting area extraction model based on improved DeepLabv3+ and CBAM.” Remote Sensing 15, no. 17 (2023): 4156.</p> <p>• Luo, Yana, and Zhongsheng Wang. “An improved resnet algorithm based on cbam.” In 2021 International Conference on Computer Network, Electronic and Automation (ICCNEA), pp. 121-125. IEEE, 2021.</p> <p>• Chen, Yantong, Xianzhong Zhang, Weinan Chen, Yuyang Li, and Junsheng Wang. “Research on recognition of fly species based on improved RetinaNet and CBAM.” IEEE Access 8 (2020): 102907-102919.</p> <p>• Fu, Huixuan, Guoqing Song, and Yuchao Wang. “Improved YOLOv4 marine target detection combined with CBAM.” Symmetry 13, no. 4 (2021): 623.</p> </body></html>